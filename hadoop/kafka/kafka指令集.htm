<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>kafka指令集</title>
<style>
.table{
	
	width:100%;
	margin-left:10px;
	
}
.table tr td{
	
	border:1px solid black;
}

</style>
</head>

<body>
<h4>kafka指令集</h4>
<ul style=" list-style-type: none;">
	<li>
		<table class="table" style="font-size:large;width:90%">
			
			<tr>
				<td style="width:30%;">kafka-server-start.sh $KAFKA_HOME/conf/server.properties</td>
				<td style="width:70%;">通过配置文件 启动一个broker 同一集群下server.properties里的brokerid 必须不一样</td>
			</tr>
			<tr>
				<td style="width:30%;">&nbsp;</td>
				<td style="width:70%;">&nbsp;</td>
			</tr>
			<tr>
				<td style="width:30%;">kafka-topics.sh --describe --zookeeper 10.10.0.65</td>
				<td style="width:70%;">查看kafka下有的topic信息</td>
			</tr>
			<tr>
				<td style="width:30%;">kafka-topics.sh --create --zookeeper 10.10.0.65 --topic test --partitions 2 --replication-factor 1 </td>
				<td style="width:70%;">zookeeper 集群管理下 创建名为test的topic 分区为2 备份为1</td>
			</tr>
			
			<tr>
				<td style="width:30%;">kafka-topics.sh --alter --zookeeper 10.10.0.65 --topic test --partitions 3</td>
				<td style="width:70%;">修改zookeeper 集群管理的 kafka topic 为test 的partitions 为 3 </td>
			</tr>
			<tr>
				<td style="width:30%;">kafka-topics.sh --delete --zookeeper 10.10.0.65 --topic test</td>
				<td style="width:70%;">删除zookeeper 集群管理的 kafka 名称为test的topic <br/>
										需要在$kafka_home/conf/server.properties 添加配置  
										<br />delete.topic.enable=true
				</td>
			</tr>
			
			<tr>
				<td style="width:30%;">&nbsp;</td>
				<td style="width:70%;">&nbsp;</td>
			</tr>
			<tr>
				<td style="width:30%;">kafka-console-producer.sh --broker-list 10.10.0.67:9092 --topic storm</td>
				<td style="width:70%;">使用console打印输入的方式 往broker 下topic storm 发送信息</td>
			</tr>
			<tr>
				<td style="width:30%;">kafka-console-consumer.sh --zookeeper 10.10.0.66:2181 --topic storm</td>
				<td style="width:70%;">使用console打印输出的方式 接受zookeeper集群中的 topic storm 的数据</td>
			</tr>

		</table>
		

	</li>
	<br/>
	


</ul>


<h4>kafka 元数据</h4>
<ul style=" list-style-type: decimal;">
	<li>broker:一台kafka服务器就是一个broker<br/>
			broker启动后，会在zookeeper上/brokers/ids 下注册此服务器的信息
	</li>
	<br/>
	<li>Producer :往kafka发消息的客户端
	</li>
	<br/>
	<li>consumers:从kafka取消息的客户端<br/>
			consumers启动后，会在zookeeper上/consumers 下注册consumers group 与 topic 的信息
	</li>
	<br/>
	
	<li>Partition:多线程的topic
	</li>
	<br/>
	
	<li>
	</li>
	<br/>

</ul>


<h4>kafka 原理</h4>
<ul style=" list-style-type: decimal;">
	<li>PageCache优化：
		<br/>
		&nbsp;&nbsp;&nbsp;
		Kafka重度依赖底层操作系统提供的PageCache功能。当上层有写操作时，操作系统只是将数据写入PageCache，同时标记Page属性为Dirty。
		当读操作发生时，先从PageCache中查找，如果发生缺页才进行磁盘调度，最终返回需要的数据。实际上PageCache是把尽可能多的空闲内存都
		当做了磁盘缓存来使用。同时如果有其他进程申请内存，回收PageCache的代价又很小，所以现代的OS（操作系统）都支持PageCache
		<br/>
		&nbsp;&nbsp;&nbsp;
PageCache功能同时可以避免在JVM内部缓存数据，JVM为我们提供了强大的GC能力，同时也引入了一些问题不适用与Kafka的设计
<br/>
		&nbsp;&nbsp;&nbsp;

如果Kafka重启，所有的In-Process Cache都会失效，而OS管理的PageCache依然可以继续使用。<br/>
	</li>
	<br/>
	<li>Sendfile优化：
		<br/>
		传统的网络I/O<br/>

		&nbsp;&nbsp;&nbsp;
a.    OS 从硬盘把数据读到内核区的PageCache。<br/>
&nbsp;&nbsp;&nbsp;

b.    应用进程把数据从内核区Copy到用户区。<br/>
&nbsp;&nbsp;&nbsp;

c.    然后应用进程再把数据写入到Socket，数据流入内核区的Socket Buffer上。<br/>
&nbsp;&nbsp;&nbsp;

d.    OS 再把数据从Buffer中Copy到网卡的Buffer上，这样完成一次发送。<br/>
		优化之后：<br/>
				&nbsp;&nbsp;&nbsp;
a.    OS 从硬盘把数据读到内核区的PageCache。<br/>
	&nbsp;&nbsp;&nbsp; b. 应用进程把数据从内核区写入到Socket，数据流入内核区的Socket Buffer上。<br/>
&nbsp;&nbsp;&nbsp;

	c.    OS 再把数据从Buffer中Copy到网卡的Buffer上，这样完成一次发送。<br/>
省掉应用层面<br/>
Kafka的设计初衷是尽一切努力在内存中完成数据交换，无论是对外作为一整个消息系统，或是内部同底层操作系统的交互。<br/>
	</li>
	
	
<li>
		<br/>
	</li>
	<br/>
<li>
		<br/>
	</li>
	<br/>

</ul>

</body>

</html>
